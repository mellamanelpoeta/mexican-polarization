{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "> This is the class that creates the dictionary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#negative_words file\n",
    "df = pd.read_csv('negative_words.csv')\n",
    "df = df.drop(columns=['original']) #drop it since it contains the concept with an * in it\n",
    "\n",
    "neg_words = [] \n",
    "for _, row in df.iterrows():\n",
    "    for item in row:\n",
    "        if pd.notnull(item):\n",
    "            neg_words.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop duplicates in neg_words:\n",
    "neg_words = list(set(neg_words))\n",
    "\n",
    "len(neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moralidad']\n",
      "['moral']\n",
      "['etica']\n",
      "['etico']\n",
      "['principios']\n",
      "['valores']\n",
      "['bueno', ' buena']\n",
      "['bondadoso']\n",
      "['correcto']\n",
      "['erroneo', ' equivocado', ' incorrecto', ' malo']\n",
      "['justicia']\n",
      "['fechoria', ' pecado', ' indebido']\n",
      "['virtud']\n",
      "['vicioso']\n",
      "['moralidad']\n",
      "['etica']\n",
      "vice examples:  ['destruccion', ' perjudicar', 'perjudicar', ' ataque', 'explota', ' abusivo', 'abandonar', ' matar', 'fanatismo', 'plantado']\n",
      "virtue examples:  [' justicia', 'comunal', 'miembro', 'justicia', 'permitir', ' simpatizar', 'modestia', 'posicion', 'diferir', ' sometido']\n"
     ]
    }
   ],
   "source": [
    "#moral_foundations_dictionary file:\n",
    "df = pd.read_csv('moral_foundations_dictionary_1.0.csv')\n",
    "df = df[['categories','word_examples']]\n",
    "\n",
    "virtue = []\n",
    "vice = []\n",
    "for _, row in df.iterrows():\n",
    "    if pd.notnull(row['word_examples']):\n",
    "        words = row['word_examples'].split(',')\n",
    "        if 'Virtue' in row['categories']:\n",
    "            virtue.extend(words)\n",
    "        elif 'Vice' in row['categories']:\n",
    "            vice.extend(words)\n",
    "        else:\n",
    "            print(words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vice examples:  ['incorrecto', 'destruccion', ' perjudicar', ' ataque', 'perjudicar', 'explota', ' abusivo', 'abandonar', ' matar', 'fanatismo']\n",
      "virtue examples:  [' justicia', 'comunal', 'miembro', 'justicia', 'modestia', 'permitir', ' simpatizar', 'posicion', 'diferir', ' sometido']\n"
     ]
    }
   ],
   "source": [
    "virtue.extend(['moralidad','moral','etica','etico','principios','valores','bueno','buena','bondadoso','correcto','justicia','virtud','moralidad','etica'])\n",
    "vice.extend(['erroneo','equivocado','incorrecto','malo','fechoria','pecado','indebido','vicioso'])\n",
    "#Drop duplicates in virtue and vice:\n",
    "virtue = list(set(virtue))\n",
    "vice = list(set(vice))\n",
    "\n",
    "print('vice examples: ', vice[:10])\n",
    "print('virtue examples: ', virtue[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the vectors data frame:\n",
    "def load_embeddings(file_path):\n",
    "    word_to_vec = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            word_to_vec[word] = vector\n",
    "    return word_to_vec\n",
    "\n",
    "word_to_vec = load_embeddings('vectorspol.txt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Classifier:\n",
    "\n",
    "    def load_embeddings(file_path):\n",
    "        '''Loads the embeddings from a file and returns a dictionary with the words as keys and the vectors as values'''\n",
    "        word_to_vec = {}\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vector = np.array(values[1:], dtype='float32')\n",
    "                print(vector.shape)\n",
    "                word_to_vec[word] = vector\n",
    "        return word_to_vec\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env-web-scrap",
   "language": "python",
   "name": ".env-web-scrap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
