{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "> This is the class that creates the dictionary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#negative_words file\n",
    "df = pd.read_csv('negative_words.csv')\n",
    "df = df.drop(columns=['original']) #drop it since it contains the concept with an * in it\n",
    "\n",
    "neg_words = [] \n",
    "for _, row in df.iterrows():\n",
    "    for item in row:\n",
    "        if pd.notnull(item):\n",
    "            neg_words.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop duplicates in neg_words:\n",
    "neg_words = list(set(neg_words))\n",
    "\n",
    "len(neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moralidad']\n",
      "['moral']\n",
      "['etica']\n",
      "['etico']\n",
      "['principios']\n",
      "['valores']\n",
      "['bueno', ' buena']\n",
      "['bondadoso']\n",
      "['correcto']\n",
      "['erroneo', ' equivocado', ' incorrecto', ' malo']\n",
      "['justicia']\n",
      "['fechoria', ' pecado', ' indebido']\n",
      "['virtud']\n",
      "['vicioso']\n",
      "['moralidad']\n",
      "['etica']\n"
     ]
    }
   ],
   "source": [
    "#moral_foundations_dictionary file:\n",
    "df = pd.read_csv('moral_foundations_dictionary_1.0.csv')\n",
    "df = df[['categories','word_examples']]\n",
    "\n",
    "virtue = []\n",
    "vice = []\n",
    "for _, row in df.iterrows():\n",
    "    if pd.notnull(row['word_examples']):\n",
    "        words = row['word_examples'].split(',')\n",
    "        if 'Virtue' in row['categories']:\n",
    "            virtue.extend(words)\n",
    "        elif 'Vice' in row['categories']:\n",
    "            vice.extend(words)\n",
    "        else:\n",
    "            print(words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vice examples:  ['incorrecto', 'destruccion', ' perjudicar', 'perjudicar', ' ataque', 'explota', ' abusivo', 'abandonar', ' matar', 'fanatismo']\n",
      "virtue examples:  [' justicia', 'comunal', 'miembro', 'justicia', 'permitir', ' simpatizar', 'modestia', 'posicion', 'diferir', ' sometido']\n"
     ]
    }
   ],
   "source": [
    "virtue.extend(['moralidad','moral','etica','etico','principios','valores','bueno','buena','bondadoso','correcto','justicia','virtud','moralidad','etica'])\n",
    "vice.extend(['erroneo','equivocado','incorrecto','malo','fechoria','pecado','indebido','vicioso'])\n",
    "#Drop duplicates in virtue and vice:\n",
    "virtue = list(set(virtue))\n",
    "vice = list(set(vice))\n",
    "\n",
    "print('vice examples: ', vice[:10])\n",
    "print('virtue examples: ', virtue[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the vectors data frame:\n",
    "def load_embeddings(file_path):\n",
    "    word_to_vec = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            word_to_vec[word] = vector\n",
    "    return word_to_vec\n",
    "\n",
    "word_to_vec = load_embeddings('vectorspol.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = set(vice)\n",
    "two = set(neg_words)\n",
    "\n",
    "vice = list(one.union(two))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1936\n"
     ]
    }
   ],
   "source": [
    "print(len(vice)+len(virtue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Classifier:\n",
    "    def __init__(self):\n",
    "        self.embeddings = None\n",
    "        self.vice = None\n",
    "        self.virtue = None\n",
    "\n",
    "    def load_embeddings(file_path):\n",
    "        '''Loads the embeddings from a file and returns a dictionary with the words as keys and the vectors as values'''\n",
    "        word_to_vec = {}\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vector = np.array(values[1:], dtype='float32')\n",
    "                print(vector.shape)\n",
    "                word_to_vec[word] = vector\n",
    "        self.embeddings = word_to_vec\n",
    "        return word_to_vec\n",
    "    \n",
    "    \n",
    "    def list_to_vec(self,\n",
    "                    vice:list,  #list of vice words\n",
    "                    virtue:list):   #list of virtue words\n",
    "        '''Returns the vector representation of a list of words in a df'''\n",
    "        df = pd.DataFrame(columns=['word','vector','category'])\n",
    "        for word in vice:\n",
    "            if word in word_to_vec.keys():\n",
    "                df = df.append({'word':word,'vector':word_to_vec[word],'category':'vice'},ignore_index=True)\n",
    "            else:\n",
    "                df = df.append({'word':word,'vector':np.zeros(300),'category':'vice'},ignore_index=True)\n",
    "        for word in virtue:\n",
    "            if word in word_to_vec.keys():\n",
    "                df = df.append({'word':word,'vector':np.nan,'category':'virtue'},ignore_index=True)\n",
    "            else:\n",
    "                df = df.append({'word':word,'vector':np.nan,'category':'virtue'},ignore_index=True)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words:  1936\n",
      "Total words after dropping NaN:  1015\n",
      "∆:  921\n",
      "∆%: 47.57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>vector</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perdimos</td>\n",
       "      <td>[-0.105455, -0.209274, -0.443211, -0.021088, 0...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fracaso</td>\n",
       "      <td>[-0.031448, -0.209139, 0.20089, 0.257588, -0.4...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peligro</td>\n",
       "      <td>[0.117094, 0.134832, 0.638222, 0.580737, -0.06...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interrupcion</td>\n",
       "      <td>[0.319177, -0.141361, -0.873159, 0.273652, -0....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>defectuoso</td>\n",
       "      <td>[0.087096, -0.162107, 0.13108, -0.164852, 0.52...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>cumplir</td>\n",
       "      <td>[0.346516, -0.015141, 0.138794, -0.021297, -0....</td>\n",
       "      <td>virtue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>correcto</td>\n",
       "      <td>[0.071845, -0.322979, -0.259893, 0.400886, 0.3...</td>\n",
       "      <td>virtue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>bueno</td>\n",
       "      <td>[0.717693, 0.01057, 0.502308, 0.411575, -0.427...</td>\n",
       "      <td>virtue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>comunidad</td>\n",
       "      <td>[0.044601, 0.356975, 0.119808, -0.21727, 0.386...</td>\n",
       "      <td>virtue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>equitativo</td>\n",
       "      <td>[-0.262624, -0.685065, -0.025029, 0.684007, -0...</td>\n",
       "      <td>virtue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1015 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word                                             vector category\n",
       "0         perdimos  [-0.105455, -0.209274, -0.443211, -0.021088, 0...      0.0\n",
       "1          fracaso  [-0.031448, -0.209139, 0.20089, 0.257588, -0.4...      0.0\n",
       "2          peligro  [0.117094, 0.134832, 0.638222, 0.580737, -0.06...      0.0\n",
       "3     interrupcion  [0.319177, -0.141361, -0.873159, 0.273652, -0....      0.0\n",
       "4       defectuoso  [0.087096, -0.162107, 0.13108, -0.164852, 0.52...      0.0\n",
       "...            ...                                                ...      ...\n",
       "1010       cumplir  [0.346516, -0.015141, 0.138794, -0.021297, -0....   virtue\n",
       "1011      correcto  [0.071845, -0.322979, -0.259893, 0.400886, 0.3...   virtue\n",
       "1012         bueno  [0.717693, 0.01057, 0.502308, 0.411575, -0.427...   virtue\n",
       "1013     comunidad  [0.044601, 0.356975, 0.119808, -0.21727, 0.386...   virtue\n",
       "1014    equitativo  [-0.262624, -0.685065, -0.025029, 0.684007, -0...   virtue\n",
       "\n",
       "[1015 rows x 3 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_to_vec(vice, virtue, word_to_vec):\n",
    "    '''Returns the vector representation of a list of words in a df'''\n",
    "    data = {'word': [], 'vector': [], 'category': []}\n",
    "    for word in vice:\n",
    "        if word in word_to_vec.keys():\n",
    "            data['word'].append(word)\n",
    "            data['vector'].append(word_to_vec[word])\n",
    "            data['category'].append(0.0) #vice will be represented as 0\n",
    "        else:\n",
    "            data['word'].append(word)\n",
    "            data['vector'].append(np.nan)\n",
    "            data['category'].append(1.0) #virtue will be represented as 1\n",
    "    \n",
    "    for word in virtue:\n",
    "        if word in word_to_vec.keys():\n",
    "            data['word'].append(word)\n",
    "            data['vector'].append(word_to_vec[word])\n",
    "            data['category'].append('virtue')\n",
    "        else:\n",
    "            data['word'].append(word)\n",
    "            data['vector'].append(np.nan)\n",
    "            data['category'].append('virtue')\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "df = list_to_vec(vice,virtue,word_to_vec)\n",
    "total = len(df)\n",
    "print('Total words: ',total)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "print('Total words after dropping NaN: ',len(df))\n",
    "print('∆: ',total-len(df))\n",
    "print('∆%:', round((total-len(df))/total*100,2) )\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env-web-scrap",
   "language": "python",
   "name": ".env-web-scrap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
